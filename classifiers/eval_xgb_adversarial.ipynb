{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6152c4-bc3d-4631-8256-498ac2023c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 99)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb9cff-1810-4780-8ccc-3309f908b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../../data-new/\")\n",
    "assert ROOT.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"corpus_metadata.csv\")\n",
    "test = df.query('subset == \"test\"')\n",
    "test_hashes = set(test[\"sha256\"])\n",
    "test_dirty_hashes = set(df.query('subset == \"test\" & label == \"dirty\"')[\"sha256\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619a510-6f7c-47fa-9fea-46420f0ba8b3",
   "metadata": {},
   "source": [
    "# CSVs + sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074f4a5-2b2f-47a5-ac46-9987cda4a0e8",
   "metadata": {},
   "source": [
    "## GPT4o + CONSTRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe5b39-4d25-4ced-8dee-11b6d926c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = ROOT / \"adversarial/metadata/gpt4o-adversarial-generation-results_with_mapping_label_filtered.csv\"\n",
    "print(CSV.resolve().as_posix())\n",
    "SAMPLES = ROOT / \"adversarial/data/gpt4o-adversarial-generation-results/all_modified/\"\n",
    "print(SAMPLES.resolve().as_posix())\n",
    "assert CSV.exists()\n",
    "assert SAMPLES.exists() and SAMPLES.is_dir()\n",
    "\n",
    "xs = pd.read_csv(CSV)\n",
    "# no .py suffix\n",
    "\n",
    "assert set(xs[\"filename\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "\n",
    "assert len(xs) == 772\n",
    "# assert (n := len(list(SAMPLES.iterdir()))) == 774, n\n",
    "for f in xs[\"filename\"]:\n",
    "    assert (SAMPLES / f).exists(), f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e67ff7-8e03-4564-bb7c-2385f68a09ca",
   "metadata": {},
   "source": [
    "## GPT4o + CONSTRAINED + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deacc4f-18ba-4150-b417-9a68f8379c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = ROOT / \"adversarial/metadata/gpt4o_rag_with_mapping_label_filtered.csv\"\n",
    "print(CSV.resolve().as_posix())\n",
    "SAMPLES = ROOT / \"adversarial/data/gpt4o-rag-generation/gpt4o-adversarial-generation-results/new_prompt-modified/\"\n",
    "print(SAMPLES.resolve().as_posix())\n",
    "assert CSV.exists()\n",
    "assert SAMPLES.exists() and SAMPLES.is_dir()\n",
    "\n",
    "xs = pd.read_csv(CSV)\n",
    "# no .py suffix\n",
    "\n",
    "assert set(xs[\"filename\"]) <= set(df[\"sha256\"])\n",
    "\n",
    "assert len(xs) == 666\n",
    "assert len(list(SAMPLES.iterdir())) == 799\n",
    "for f in xs[\"filename\"]:\n",
    "    assert (SAMPLES / f).exists(), f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace8d88-1e4c-4ea6-a4cf-17b57d3702bc",
   "metadata": {},
   "source": [
    "## GPT4o + UNCONSTRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc7f35-1695-4091-aea8-ab0a0bf8e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = ROOT / \"adversarial/metadata/gpt4o-scripts-full-unconstrained-parsable_with_mapping_label_filtered.csv\"\n",
    "print(CSV.resolve().as_posix())\n",
    "SAMPLES = ROOT / \"adversarial/data/gpt4o-unconstrained-parseable-scripts/gpt4o_scripts_full_unconstrained_ast_parsable/\"\n",
    "print(SAMPLES.resolve().as_posix())\n",
    "assert CSV.exists()\n",
    "assert SAMPLES.exists() and SAMPLES.is_dir()\n",
    "\n",
    "xs = pd.read_csv(CSV)\n",
    "# no .py suffix\n",
    "\n",
    "# assert set(xs[\"filename\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "assert set(xs[\"sha256\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "\n",
    "assert len(xs) == 1650\n",
    "assert len(list(SAMPLES.iterdir())) == 1671\n",
    "for f in xs[\"sha256\"]:\n",
    "    assert (SAMPLES / f).exists(), f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12b910-e2ea-451b-b235-8dc372045841",
   "metadata": {},
   "source": [
    "## Llama + CONSTRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74adc647-2f34-408c-8e40-31d69c6723b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = ROOT / \"adversarial/metadata/llama_full_parsable_scripts_with_mapping_label_filtered.csv\"\n",
    "print(CSV.resolve().as_posix())\n",
    "SAMPLES = ROOT / \"adversarial/data/llama_parsable_scripts_full/llama-full/parsable_scripts/\"\n",
    "print(SAMPLES.resolve().as_posix())\n",
    "assert CSV.exists()\n",
    "assert SAMPLES.exists() and SAMPLES.is_dir()\n",
    "\n",
    "xs = pd.read_csv(CSV)\n",
    "# no .py suffix\n",
    "\n",
    "# assert set(xs[\"filename\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "assert set(xs[\"sha256\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "\n",
    "assert len(xs) == 909\n",
    "assert len(list(SAMPLES.iterdir())) == 1147\n",
    "for f in xs[\"sha256\"]:\n",
    "    assert (SAMPLES / f).exists(), f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd4375-d9b9-4d6b-8462-e3242af7b52e",
   "metadata": {},
   "source": [
    "## Llama + UNCONSTRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a65ae-7572-4abc-bf1b-5ba20cad5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = ROOT / \"adversarial/metadata/llama-scripts-full-unconstrained-parsable_with_mapping_label_filtered.csv\"\n",
    "print(CSV.resolve().as_posix())\n",
    "SAMPLES = ROOT / \"adversarial/data/llama-unconstrained-parseable-scripts/\"\n",
    "print(SAMPLES.resolve().as_posix())\n",
    "assert CSV.exists()\n",
    "assert SAMPLES.exists() and SAMPLES.is_dir()\n",
    "\n",
    "xs = pd.read_csv(CSV)\n",
    "# no .py suffix\n",
    "\n",
    "# assert set(xs[\"filename\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "assert set(xs[\"sha256\"]) <= set(df.query('subset == \"test\"')[\"sha256\"])\n",
    "\n",
    "assert len(xs) == 1416\n",
    "assert len(list(SAMPLES.iterdir())) == 1595\n",
    "for f in xs[\"sha256\"]:\n",
    "    assert (SAMPLES / f).exists(), f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d690f96-8b72-46de-a9f9-9a9ff82a5c07",
   "metadata": {},
   "source": [
    "## Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f521a-c72f-4fb2-b086-0c2296d9d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"add_comments\", \"add_documentation\", \"add_padding\"]:\n",
    "    s = Path(\"../../data-new/adversarial/data/heuristically-generated-new\") / k\n",
    "    assert s.exists()\n",
    "    files = list(s.iterdir())\n",
    "    names = [f.name.split(\"_\")[0] for f in files]\n",
    "    print(k, len(names))\n",
    "    pd.DataFrame({\"sha256\": [f.name for f in files]}).to_csv(\n",
    "        f\"../../data-new/adversarial/metadata/heu_{k}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75311e-3b25-40e4-a44e-496a617872f4",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc0ff9-5218-4b8c-a8dc-cfffa264266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred, thr):\n",
    "    acc = 0\n",
    "    for f, dv in pred.items():\n",
    "        acc += dv >= thr\n",
    "    return (acc / len(pred)).item()\n",
    "\n",
    "\n",
    "def label_change(pv, pa, thr):\n",
    "    cnt = Counter()\n",
    "\n",
    "    for f, dv_van in pv.items():\n",
    "        dv_adv = pa[f]\n",
    "\n",
    "        rv = [\"und\", \"det\"][int(dv_van >= thr)]\n",
    "        ra = [\"und\", \"det\"][int(dv_adv >= thr)]\n",
    "\n",
    "        cnt[(rv, ra)] += 1\n",
    "\n",
    "    return dict(cnt)\n",
    "\n",
    "\n",
    "def dv_diff(pv, pa):\n",
    "    pos = []\n",
    "    neg = []\n",
    "    for f, dv_van in pv.items():\n",
    "        dv_adv = pa[f]\n",
    "        diff = dv_van - dv_adv\n",
    "        if diff >= 0:\n",
    "            pos.append(diff)\n",
    "        else:\n",
    "            neg.append(diff)\n",
    "    res = {\"pos_diff\": len(pos), \"neg_diff\": len(neg)}\n",
    "    for func in [\"mean\", \"median\", \"std\"]:\n",
    "        res |= {\n",
    "            f\"{func}_pos_diff\": getattr(np, func)(pos).item() if pos else None,\n",
    "            f\"{func}_neg_diff\": getattr(np, func)(neg).item() if neg else None,\n",
    "        }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b6dbc-cba6-4007-9aed-5ae657de2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_heu_names(xs):\n",
    "    return [x.split(\"_\")[0] for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b871a-3051-4ac8-b63f-220ed538d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME = \"pred_gpt4o_constrained\"\n",
    "# NAME = \"pred_gpt4o_constrained_rag\"\n",
    "# NAME = \"pred_gpt4o_unconstrained\"\n",
    "# NAME = \"pred_llama_constrained\"\n",
    "# NAME = \"pred_llama_unconstrained\"\n",
    "# NAME = \"pred_heu_add_comments\"\n",
    "# NAME = \"pred_heu_add_documentation\"\n",
    "NAME = \"pred_heu_add_padding\"\n",
    "\n",
    "pred_adv = pd.read_parquet(f\"{NAME}.parquet\").set_index(\"run_id\")\n",
    "\n",
    "if \"heu\" in NAME:\n",
    "    pred_adv[\"files\"] = pred_adv[\"files\"].apply(normalise_heu_names)\n",
    "\n",
    "thrs = pd.read_csv(\"vanilla_f1_thr.csv\").set_index(\"run_id\")[\"thr_f1\"].to_dict()\n",
    "exps2fxs = pd.read_csv(\"exp_ids_to_fx_funcs.csv\").set_index(\"run_id\")[\"fx_funcs\"].to_dict()\n",
    "exps = list(thrs.keys())\n",
    "pred_van = pd.read_parquet(\"xgb_vanilla_test.parquet\").set_index(\"run_id\")\n",
    "\n",
    "assert 255 == len(pred_adv) == len(pred_van) == len(exps) == len(exps2fxs)\n",
    "\n",
    "results = []\n",
    "for exp in tqdm(exps):\n",
    "    v = pred_van.loc[exp]\n",
    "    a = pred_adv.loc[exp]\n",
    "    if \"labels\" in a:\n",
    "        assert (a[\"labels\"] == 1).all()\n",
    "    assert set(a[\"files\"]) <= set(v[\"files\"])\n",
    "\n",
    "    idx = [i for i, x in enumerate(v[\"files\"]) if x in a[\"files\"]]\n",
    "    assert len(idx) == len(a[\"files\"])\n",
    "    assert sorted([v[\"files\"][i] for i in idx]) == sorted(a[\"files\"])\n",
    "\n",
    "    pv = {v[\"files\"][i]: v[\"preds\"][i] for i in idx}\n",
    "    pa = dict(zip(a[\"files\"], a[\"preds\"]))\n",
    "    assert len(pv) == len(pa)\n",
    "    assert pv.keys() == pa.keys()\n",
    "\n",
    "    res = {\n",
    "        \"exp\": exp,\n",
    "        \"fx_funcs\": exps2fxs[exp],\n",
    "    }\n",
    "    res |= {\n",
    "        \"acc_van_05\": acc(pv, 0.5),\n",
    "        \"acc_van_custom\": acc(pv, thrs[exp]),\n",
    "        \"acc_adv_05\": acc(pa, 0.5),\n",
    "        \"acc_adv_custom\": acc(pa, thrs[exp]),\n",
    "    }\n",
    "    res |= {f\"{a}->{b}_05\": k for (a, b), k in label_change(pv, pa, 0.5).items()}\n",
    "    res |= {f\"{a}->{b}_custom\": k for (a, b), k in label_change(pv, pa, thrs[exp]).items()}\n",
    "    res |= dv_diff(pv, pa)\n",
    "\n",
    "    results.append(res)\n",
    "    # P(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e566f-8ba8-4a16-8d25-58da3120f987",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5413c-4624-4b28-9c6d-410843bda854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NAME)\n",
    "for l in [\"adv\", \"van\"]:\n",
    "    print(\"\\n\", l)\n",
    "    for t in [\"05\", \"custom\"]:\n",
    "        for func in [\"mean\", \"median\", \"std\"]:\n",
    "            x = getattr(np, func)([r[f\"acc_{l}_{t}\"] for r in res])\n",
    "            print(f\"{func} acc @ thr={t}: {x:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde9408-9230-4a03-b2dc-1fdfad4c2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NAME)\n",
    "for t in [\"05\", \"custom\"]:\n",
    "    key = f\"label_change_{t}\"\n",
    "\n",
    "    xs = np.mean([(r.get(f\"det->und_{t}\", 0) / (r.get(f\"det->det_{t}\", 0) + r.get(f\"det->und_{t}\", 0))) for r in res])\n",
    "    print(f\"mean (det->und)|det @ {t}: {xs:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
